# vLLM Nemotron Nano VL 8B Deployment for microk8s
# Deploys nvidia/Llama-3.1-Nemotron-Nano-VL-8B-V1 using ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0
# Exposes NodePort 30566 for external access

apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-nemotron-nano-vl-8b
  namespace: spellingbee
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels: { app: vllm-nemotron-nano-vl-8b }
  template:
    metadata:
      labels: { app: vllm-nemotron-nano-vl-8b }
    spec:
      runtimeClassName: nvidia
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-GB10
      containers:
        - name: vllm
          image: ghcr.io/elizabetht/token-labs/vllm-serve:v0.4.0
          ports:
            - containerPort: 5566
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
            - name: VLLM_VIDEO_LOADER_BACKEND
              value: "opencv"
            - name: FLASHINFER_DISABLE_VERSION_CHECK
              value: "1"
          resources:
            limits:
              nvidia.com/gpu: 1
          args:
            - "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-FP8"
            - "--trust-remote-code"
            - "--gpu-memory-utilization"
            - "0.3"
            - "--attention-backend"
            - "FLASHINFER"
            - "--port"
            - "5566"
          volumeMounts:
            - name: hf-cache
              mountPath: /root/.cache/huggingface
      volumes:
        - name: hf-cache
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: vllm-nemotron-nano-vl-8b
  namespace: spellingbee
spec:
  type: NodePort
  selector: { app: vllm-nemotron-nano-vl-8b }
  ports:
    - name: http
      port: 5566
      targetPort: 5566
      nodePort: 30566
